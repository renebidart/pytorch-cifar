{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight sharing on CIFAR10\n",
    "Pytorch-cifar models have 3x3 instead of 7x7 for the first layer. This is significantly better for smaller images??? like cifar. Without this the accuracy is <=90%\n",
    "Comparing the standard kuangliu models to my rwightman version to training this using lightning (weight-sharing repo)\n",
    "\n",
    "----\n",
    "\n",
    "## Result - Weight sharing is not helpful on CIFAR10\n",
    "\n",
    "#### Regular Convolutions:\n",
    "* Worse than pruning \n",
    "\n",
    "#### Depthwise separable convolutions:\n",
    "* Weight Sharing is not generally useful. Spatial can be used without much loss in accuracy, but this saves almost no parameters.\n",
    "* Channel wise weight sharing is worse than pruining per-paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from models import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Models - Resnet: Weight sharing isn't helpful\n",
    "* Training both for 350 epochs, same hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 acc frac: 94.79 , acc ws: 94.58 5664458\n",
      "4 acc frac: 93.9 , acc ws: 93.78 2909706\n",
      "8 acc frac: 92.27 , acc ws: 91.92 1532330\n",
      "16 acc frac: 89.51 , acc ws: 87.84 843642\n"
     ]
    }
   ],
   "source": [
    "for i in [2, 4, 8, 16]:\n",
    "    save_path = './saved_models_old/cifar10/resnet18_ws1_ch'+str(i)\n",
    "    save_path_ws = './saved_models/cifar10/resnet18_ws'+str(i)+'_ch1_dr'\n",
    "    checkpoint = torch.load(save_path + '/ckpt.pth')\n",
    "    checkpoint_ws = torch.load(save_path_ws + '/ckpt.pth')\n",
    "    print(f'{i} acc frac: {checkpoint[\"acc\"]} , acc ws: {checkpoint_ws[\"acc\"]} {checkpoint_ws[\"num_params\"]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depthwise separable convolutions: Channel vs. Spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Xception\n",
    "Weight sharing either saves very few params (spatial) or has a big accuracy decrease (channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 acc frac: 93.87 787242, acc wss: 93.87 787242, acc wsc: 93.87 787242\n",
      "2 acc frac: 92.67 232746, acc wss: 93.98 777450, acc wsc: 92.76 508714\n",
      "4 acc frac: 91.3 103338, acc wss: 93.54 772554, acc wsc: 92.82 369450\n",
      "8 acc frac: 89.25 61034, acc wss: 93.44 770106, acc wsc: 91.63 299818\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 2, 4, 8]:\n",
    "    save_path_ch = './saved_models/cifar10/vsxception_ch'+str(i)+'_wss_1_wsc_1'\n",
    "    save_path_wss = './saved_models/cifar10/vsxception_ch1_wss_'+str(i)+'_wsc_1'\n",
    "    save_path_wsc = './saved_models/cifar10/vsxception_ch1_wss_1_wsc_' + str(i)\n",
    "    checkpoint_ch = torch.load(save_path_ch + '/ckpt.pth')\n",
    "    checkpoint_wss = torch.load(save_path_wss + '/ckpt.pth')\n",
    "    checkpoint_wsc = torch.load(save_path_wsc + '/ckpt.pth')\n",
    "    print(f'{i} acc frac: {checkpoint_ch[\"acc\"]} {checkpoint_ch[\"num_params\"]}, acc wss: {checkpoint_wss[\"acc\"]} {checkpoint_wss[\"num_params\"]}, acc wsc: {checkpoint_wsc[\"acc\"]} {checkpoint_wsc[\"num_params\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 acc ch: 95.42 7649898, acc wss: 95.42 7649898, acc wsc: 95.42 7649898\n",
      "2 acc ch: 95.57 3012458, acc wss: 95.67 7617642, acc wsc: 95.43 5683818\n",
      "4 acc ch: 94.93 1627626, acc wss: 95.44 7601514, acc wsc: 95.46 4700778\n",
      "8 acc ch: 93.73 1168682, acc wss: 95.53 7593450, acc wsc: 94.98 4209258\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 2, 4, 8]:\n",
    "    save_path_ch = './saved_models/cifar10/xception_ch'+str(i)+'_wss_1_wsc_1'\n",
    "    save_path_wss = './saved_models/cifar10/xception_ch1_wss_'+str(i)+'_wsc_1'\n",
    "    save_path_wsc = './saved_models/cifar10/xception_ch1_wss_1_wsc_' + str(i)\n",
    "    checkpoint_ch = torch.load(save_path_ch + '/ckpt.pth')\n",
    "    checkpoint_wss = torch.load(save_path_wss + '/ckpt.pth')\n",
    "    checkpoint_wsc = torch.load(save_path_wsc + '/ckpt.pth')\n",
    "    print(f\"\"\"{i} acc ch: {checkpoint_ch[\"acc\"]} {checkpoint_ch[\"num_params\"]}, acc wss: {checkpoint_wss[\"acc\"]} {checkpoint_wss[\"num_params\"]}, acc wsc: {checkpoint_wsc[\"acc\"]} {checkpoint_wsc[\"num_params\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Mobile Net - Baseline Accuracy too low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 acc ws: 91.53\n"
     ]
    }
   ],
   "source": [
    "save_path_ws = './saved_models/cifar10/mobile'\n",
    "checkpoint = torch.load(save_path_ws + '/ckpt.pth')\n",
    "acc_ws = checkpoint['acc']\n",
    "print(f'{i} acc ws: {acc_ws}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 acc ws: 91.87\n",
      "2 acc ws: 91.58\n",
      "4 acc ws: 92.04\n",
      "8 acc ws: 91.49\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 2, 4, 8]:\n",
    "    save_path_ws = './saved_models/cifar10/mobile_wss'+str(i)\n",
    "    checkpoint = torch.load(save_path_ws + '/ckpt.pth')\n",
    "    acc_ws = checkpoint['acc']\n",
    "    print(f'{i} acc ws: {acc_ws}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks\n",
    "* BatchNorm before and after repeat is the same\n",
    "* Cifar adjusted rwightman one == kuangliu(resnet18_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './saved_models/cifar10/resnet18_std'\n",
    "checkpoint = torch.load(save_path + '/ckpt.pth')\n",
    "checkpoint['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ws in [1, 2, 4, 8, 16]:\n",
    "    save_path = './saved_models/cifar10/resnet18_ws'+str(ws)+'_ch1'\n",
    "    save_path_bn = './saved_models/cifar10/resnet18bn_ws'+str(ws)+'_ch1'\n",
    "    checkpoint = torch.load(save_path + '/ckpt.pth')\n",
    "    acc = checkpoint['acc']\n",
    "    checkpoint = torch.load(save_path_bn + '/ckpt.pth')\n",
    "    acc_bn = checkpoint['acc']\n",
    "    print(f'{ws} acc: {acc} acc_bn: {acc_bn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './saved_models/cifar10/resnet50_ws1_ch1'\n",
    "checkpoint = torch.load(save_path + '/ckpt.pth')\n",
    "checkpoint['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet (rwightman) vs. cifar (kuangliu) resnets\n",
    "Weight differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_model = ResNetLight(BasicBlockLight, [2, 2, 2, 2], ws_factor=1, channel_factor=1,\n",
    "                         num_classes=10, cifar=False)\n",
    "cifar_model = ResNet18()\n",
    "\n",
    "\n",
    "imagenet_model_names = []\n",
    "imagenet_model_sizes = []\n",
    "for name, param in imagenet_model.named_parameters():\n",
    "    imagenet_model_names.append(name)\n",
    "    imagenet_model_sizes.append(param.size())\n",
    "    \n",
    "cifar_model_names = []\n",
    "cifar_model_sizes = []\n",
    "for name, param in cifar_model.named_parameters():\n",
    "    cifar_model_names.append(name)\n",
    "    cifar_model_sizes.append(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,m in zip(cifar_model_sizes, imagenet_model_sizes):\n",
    "    print(n,  m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,m in zip(cifar_model_names, imagenet_model_names):\n",
    "    print(n + '\\t\\t\\t' + m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug strides, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_model.to('cuda')\n",
    "y = imagenet_model(torch.randn(2,3,32,32).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_model.to('cuda')\n",
    "y = cifar_model(torch.randn(2,3,32,32).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_model = ResNetLight(BasicBlockLight, [2, 2, 2, 2], ws_factor=1, channel_factor=1,\n",
    "                         num_classes=10, cifar=True)\n",
    "\n",
    "imagenet_model.to('cuda')\n",
    "y = imagenet_model(torch.randn(2,3,32,32).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSSL",
   "language": "python",
   "name": "lssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
